{
    "Title": "DiT: Self-supervised Pre-training for",
    "Authors": "Document Image Transformer\n\nJunlong Li\n\nlockonna@sjtu.edu.cnShanghai Jiao Tong UniversityShanghai, China\n\nYiheng Xu\n\nt-yihengxu@microsoft.comMicrosoft Research AsiaBeijing, China\n\nTengchao Lv\n\ntengchaolv@microsoft.comMicrosoft Research AsiaBeijing, China\n\nLei Cui\n\nlecu@microsoft.comMicrosoft Research AsiaBeijing, China\n\nCha Zhang\n\nchazhang@microsoft.comMicrosoft Azure AIRedmond, United States\n\nFuru Wei\n\nfuwei@microsoft.comMicrosoft Research AsiaBeijing, China",
    "Abstract": "Image Transformer has recently achieved significant progress for natural image understanding, either using supervised (ViT, DeiT, etc.) or self-supervised (BEiT, MAE, etc.) pre-training techniques. In this paper, we propose **DiT**, a self-supervised pre-trained **D**ocument **I**mage **T**ransformer model using large-scale unlabeled text images for Document AI tasks, which is essential since no supervised counterparts ever exist due to the lack of human-labeled document images. We leverage DiT as the backbone network in a variety of vision-based Document AI tasks, including document image classification, document layout analysis, table detection as well as text detection for OCR. Experiment results have illustrated that the self-supervised pre-trained DiT model achieves new state-of-the-art results on these downstream tasks, e.g. document image classification (91.11 \\(\\rightarrow\\) 92.69), document layout analysis (91.0 \\(\\rightarrow\\) 94.9), table detection (94.23 \\(\\rightarrow\\) 96.55) and text detection for OCR (93.07 \\(\\rightarrow\\) 94.29). The code and pre-trained models are publicly available at https://aka.ms/msdit.",
    "Key Findings": "In this paper, we present DiT, a self-supervised foundation model for general Document AI tasks. The DiT model is pre-trained with large-scale unlabeled document images that cover a variety of templates and formats, which is ideal for downstream Document AI tasks in different domains. We evaluate the pre-trained DiT on several vision-based Document AI benchmarks, including table detection, document layout analysis, document image classification, and text detection. Experimental results have shown that DiT outperforms several strong baselines across the board and achieves new SOTA performance. We will make the pre-trained DiT models publicly available to facilitate the Document AI research.",
    "References": [
        "(1)",
        "Afzal et al. (2017) Muhammad Zeshan Afzal, Andreas Kolsch, Shera Ahmed, and Marcus Liwicki. 2017. Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training Strategies for Document Image Classification. _2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)_ 01 (2017), 883-888.",
        "Appalaraju et al. (2021) Srikar Appalaraju, Bhavan Jasani, Bhargava Urala Kota, Yusheng Xie, and Rammatha. 2021. DoEformer: End-to-End Transformer for Document Understanding. arXiv:2106.11539 [cs.CV].",
        "Bao et al. (2021) Hangbo Bao, Li Dong, and Furu Wei. 2021. BEIT: BERT Pre-Training of Image Transformers. arXiv:2106.08254 [cs.CV].",
        "Bradski (2000) G. Bradski. 2000. The OpenCV Library. _Dr. Dobb's Journal of Software Tools_ (2000).",
        "Cai and Vasconcelos (2018) Zhaowei Cai and Nuno Vasconcelos. 2018. Cascade R-CNN: Delving Into High Quality Object Detection. In _2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 19-22, 2018_. IEEE Computer Society, 6154-6162. https://doi.org/10.1109/CVPR.2018.00644",
        "Carion et al. (2020) Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alex-Kier Kirillov, and Sergey Zagoruyko. 2020. End-to-end object detection with transformers. In _European conference on computer vision_. Springer, 213-229.",
        "Caron et al. (2021) Mathilde Caron, Hugo Tourvoxon, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bajonowski, and Armand Joulin. 2021. Emerging Properties in Self-Supervised Vision Transformers. arXiv:2104.14294 [cs.CV].",
        "Chen et al. (2020) Mark Chen, Alex Radford, Rewon Child, Jeffrey Wu, Heewo Jun, David Luan, and Hya Sutskever. 2020. Generative Pretraining From Pixels. In _Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event (Proceedings of Machine Learning Research, Vol. 119)_. PMLR, 1691-1703. http://proceedings.mlr.press/v119/chen03.html",
        "Chen et al. (2021) Xinlei Chen, Saining Xie, and Kaiming He. 2021. An Empirical Study of Training Self-Supervised Vision Transformers. arXiv:2104.02057 [cs.CV].",
        "Cui et al. (2021) Lei Cui, Yiheng Xu, Tengchao Lv, and Furu Wei. 2021. Document AI Benchmarks, Models and Applications. arXiv:2111.08609 [cs.CL].",
        "Das et al. (2018) Arindan Das, Sakid Roy, and Uhyaul Bhattacharya. 2018. Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks. _2018 24th International Conference on Pattern Recognition (ICPR)_ (2018), 3180-3185.",
        "Dosovitskiy et al. (2021) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Lyuckaert, and Neil Houlsby. 2021. An Image is Worth 1664 Works. Transformers for Image Recognition at Scale. ICLR (2021).",
        "El-Nouby et al. (2021) Alaseda El-Nouby, Hugo Tourvoxon, Matthilo Caron, Piotr Bajonowski, Matthijs Douze, Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob Verbeek, and Herve Jegou. 2021. XCVI: Cross-Covariance Image Transformers. arXiv:2106.09681 [cs.CV].",
        "Li-Nouby et al. (2021) Alaseda El-Nouby, Hugo Tourvoxon, Matthilo Caron, Piotr Bajonowski, Matthijs Douze, Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob Verbeek, and Herve Jegou. 2021. XCVI: Cross-Covariance Image Transformers. arXiv:2106.0981 [cs.CV].",
        "Gao et al. (2019) Liangca Gao, Yihan Huang, Herve Dejean, Jean-Luc Meunier, Qinqin Yan, Yu Fang, Florian Kleber, and Eva Lang. 2019. ICDAR 2019 Competition on Table Detection and Recognition (CIDAR). In _2019 International Conference on Document Analysis and Recognition (CIDAR)_. 1510-1515. https://doi.org/10.1109/ICDAR.2019.00423",
        "Harley et al. (2015) Adam W Harley, Alex Ulfkes, and Konstantinos G Derpanis. 2015. Evaluation of Deep Convolutional Nets for Document Image Classification and Retrieval. In _International Conference on Document Analysis and Recognition (ICDAR)_.",
        "He et al. (2021) Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. 2021. Masked Autoencoders Are Scalable Vision Learners. arXiv:2111.06372 [cs.CV].",
        "He et al. (2017) Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross B. Girshick. 2017. Mask R-CNN. In _IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017_. Computer Society, 2980-2988. https://doi.org/10.1109/ICCV.2017.322",
        "Hong et al. (2021) Telayku Hong, DongHyun Kim, Mingqi Ji, Wonwei Hwang, Daehyun Nam, and Sungrae Park. 2021. BROS: A Pre-trained Language Model for Understanding Texts in Document. https://openreview.net/forum?id=pmuMXQgEvPro",
        "Huang et al. (2016) Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q. Weinberger. 2016. Deep Networks with Stochastic Depth. In _ECCV_.",
        "Huang et al. (2022) Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, and Furu Wei. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. In _MM '22: The 30th ACM International Conference on Multimedia, Lisbon, Portugal, October 10-14, 2022_.",
        "Jaume et al. (2019) Guillaume Jaume, Haimi Kemal Ekenel, and Jean-Philippe Thiran. 2019. FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents. _2019 International Conference on Document Analysis and Recognition Workshops (ICDARW) 2_ (2019), 1-6.",
        "Kingma and Ba (2015) Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In _3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings_, Yoshua Bengio and Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980",
        "Lewis et al. (2006) D. Lewis, G. Agam, S. Argamon, O. Frieder, D. Grossman, and J. Heard. 2006. Building a Test Collection for Complex Document Information Processing. In _Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval_ (Seattle, Washington, USA) (SIGIR '06). ACM, New York, NY, USA, 665-666. https://doi.org/10.1145/114817.1148307",
        "Li et al. (2012) Chenliang Li, Bin Bi, Ming Yan, Wei Wang, Songfang Huang, Fei Huang, and Luo Si. 2012. StructuredAll-Structural Pre-training for Form Understanding. In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1:Long Papers)_. Association for Computational Linguistics, 6309-6318. https://doi.org/10.18653/v1/2021.acl-long-493",
        "Li et al. (2020) Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou, and Zhoujun Li. 2020. TableBank: Table Benchmark for Image-based Table Detection and Recognition. In _Proceedings of the 12th Language Resources and Evaluation Conference_. European Language Resources Association, Marseille, France, 1918-1925. https://acanthology.org/2020.lec-1236",
        "Li et al. (2020) Minghao Li, Yihong Xu, Lei Cui, Shaohan Huang, Furu Wei, Zhoujun Li, and Ming Zhou. 2020. DoEank: A Benchmark Dataset for Document Layout Analysis. In _Proceedings of the 28th International Conference on Computational Linguistics_. International Committee on Computational Linguistics, Barcelona, Spain (Online), 949-960. https://doi.org/10.18653/v1/2020.cling-main.82",
        "Li et al. (2021) Peizhao Li, Jinxiang Guo, Juxen Tu, Jul. Morait, Handong Zhao, Rajiv Jain, Varun Manjunatha, and Hongkio Lin. 2021. Selfloc-Self-Supervised Document Representation Learning. arXiv:2106.03531 [cs.CV].",
        "Li et al. (2021) Yanghao Li, Saining Xie, Xinlei Chen, Piotr Dollar, Kaiming He, and Ross B. Girshick. 2021. Benchmarking Detection Transfer Learning with Vision Transformers. arXiv:2111.11429 [cs.CV].",
        "Liao et al. (2022) Minghui Liao, Zhigheng Zou, Zhoyi Wan, Cong Yao, and Xiang Bai. 2022. Real-Time Scene Text Detection with Differentiable Binarization and Adaptive Scale Fusion. arXiv:2202.10304 [cs.CV].",
        "Liu et al. (2021) Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. 2021. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. arXiv:2103.14030 [cs.CV].",
        "Rowlaski et al. (2021) Rafal Rowlaski, Lukane Brochmann, Jourd Jukervicewicz, Tomasz Dwojak, Michal Pietruska, and Gabriela Palka. 2021. Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer. arXiv:2102.09590 [cs.CL].",
        "Prammatik et al. (2020) Subliqper Prammatik, Shashanka Mujumdar, and Hifan Patel. 2020. Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning. arXiv:2009.14457 [cs.CL].",
        "Ramesh et al. (2021) Aditya Ramesh, Mikhail Pavlov, Gabriel Gol. Scott Gray, Chelsea Voss, Alex Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-Shot Text-to-Image Generation. arXiv:2102.12092 [cs.CV].",
        "Sarkhel and Nandi (2019) Ritesh Sarkhel and Arnab Nandi. 2019. Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents. In _Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019_, Sarti Kraus (Eds.). ijcai.org, 3360-3366. https://doi.org/10.24963/ijcai.2019.466",
        "Townport et al. (2021) Huog Townport, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Salvalyrolles,* Xu et al. (2021) Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, and Furu Wei. 2021. LayoutXML Multimodal Pre-training for Multilingual Visually-rich Document Understanding. arXiv:2104.08386 [cs.CV].",
        "Xu et al. (2022) Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, and Furu Wei. 2022. XFUND: A Benchmark Dataset for Multilingual Visually Rich Form Understanding. In _Finding of the Association for Computational Linguistics: ACL 2022_. Association for Computational Linguistics, Dublin, Ireland, 3214-3224. https://doi.org/10.18653/v1/2022 findings-acl:253",
        "Xu et al. (2021) Yang Xu, Yiheng Xu, Mengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, and Lidong Zhou. 2021. LayoutLMv2: Multi-modal Pre-training for Visually-rich Document Understanding. In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_. Association for Computational Linguistics, Online, 2579-2591. https://doi.org/10.18653/v1/2021acl-long:201",
        "Zhang et al. (2020) Xu Zhong, Elaheh ShafieiBavani, and Antonio Jimenez. 2020. Image-based table recognition: data, model, and evaluation. arXiv:1911.10683 [cs.CV]",
        "Zhong et al. (2019) Xu Zhong, Jianbin Tang, and Antonio Jimenez. 2019. PuLabvNet: largest dataset ever for document layout analysis. In _2019 International Conference on Document Analysis and Recognition (ICDAR)_. IEEE, 1015-1022. https://doi.org/10.1109/ICDAR.2019.00166",
        "Zhou et al. (2017) Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Chang Xie, Alan Yuille, and Tao Kong. 2017. iBOT: Image BERT Pre-Training with Online Tokenizer. arXiv:2111.07832 [cs.CV]",
        "Garncarek et al. (2021) Lukasz Garncarek, Rafal Powalski, Tomasz Stanislawek, Bartos Topolski, Piotr Halama, Michal Turski, and Filip Gralinski. 2021. LAMBERT: Layout-Aware (Language) Modeling for information extraction. arXiv:2002.08087 [cs.CL]"
    ]
}